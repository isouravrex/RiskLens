Sn No,TECHNOLOGY,QUESTION,SOLUTION,SEVERITY,PRIORITY,CREATED_USER,CREATED_DATE,CLOSED_USER,CLOSED_DATE,RESOLUTION_TIME,CITY,Latitude,Longitude
1,Azure Service Bus,"You have configured two subnets from a single virtual network in a virtual network rule.When you try to remove one subnet using the Remove AzServiceBusVirtualNetworkRule cmdlet, it doesn't remove the subnet from the virtual network rule.","Specify the full Azure Resource Manager ID of the subnet that
includes the name of the resource group that has the virtual network.",medium,medium,Frank,09-12-2023,Iris,11-12-2023,18,Long Beach,33.85414505,-118.191597
2,Azure Service Bus,I am getting unauthorized access when attempting to access a Service Bus topic from Visual Studio on an on-premises computer using a user-assigned managed identity with send permissions.,"To resolve this error, install the Microsoft.Azure.Services. App Authentication",low,low,Frank,09-12-2023,Finn,11-12-2023,25,Hayward,37.67551041,-122.0496826
3,Azure Service Bus,"The durable entity function I've setup as output for a streaming analytics job doesn't trigger or receive any data. I can see incoming input data in the stream analytics job and it outputs to store the data correctly (for a stream analytics job storage output test I also setup). If I test the CalculatePositioni function with postman the function and entity receives the data and updates the state correctly.

I also get a binding error for the function app and I can't see what's missing:","You need to run a query on your Azure stream analytics job to make the data flow into your Azure function. Before you run the query, you would have to set the output alias name when you bind the Azure function as output to the Azure stream analytics job.",low,low,Bob,09-12-2023,James,11-12-2023,33,Compton,33.90319061,-118.2131882
4,Azure Service Bus,"I am trying to build an Azure Stream Analytics job in VS Code using the Azure Stream Analytics Tools extension. I have added an event hub as an input and a data lake gen 2 storage account as an output and I can successfully run the job in VS Code using ""Use Live Input and Live Output"".

The issue I'm having is when I try to set the output to an Azure Cosmos DB Document DB instead I get an error ""Failed to convert output 'cosmosdb' : Unsupported data source type.."" when trying to use live input and output. I can however use successfully run the job using ""Live input and local output""

Is this a limitation of the VS Code extension that you can't debug live output against Cosmos DB? Or have I set something up incorrectly in my cosmos db output?","For Live Input to Live Output mode, the only supported output 
adapters (for now) are Event Hub, Storage Account, and Azure SQL",medium,low,Bob,26-11-2020,Daniel,29-11-2020,4,Brooklyn,40.65370178,-73.9441452
5,Azure Service Bus,What is the alternative to Microsoft Azure Service Bus message?,"NServiceBus, RabbitMQ, Kafka, MSMQ, and IBM MQ are the 
most popular alternatives and competitors to Azure Service Bus.",medium,medium,Frank,12-06-2022,Harry,13-06-2022,8,El Paso,31.75202298,-106.390358
6,Azure Service Bus,Adding virtual network rule using PowerShell fails,"Specify the full Azure Resource Manager ID of the subnet that 
includes the name of the resource group that has the virtual network. ",high,medium,Bob,12-06-2022,Lucas,13-06-2022,26,Citrus Heights,38.71068573,-121.2512665
7,Azure Service Bus,	Client isn't able to establish a connection to Service Bus.,"	Make sure the supplied host name is correct and the host is reachable. If your code runs in an environment with a firewall/proxy, ensure that the traffic to the Service Bus domain/IP address and ports isn't blocked.",medium,low,Henry,12-10-2020,Harry,15-10-2020,28,Alpharetta,33.99850845,-84.2793808
8,Azure Service Bus,How do I resolve 500 internal server error in swagger?,"Install the package “Swashbuckle. AspNetCore”
Added the service in Configure service method in startup. cs.",high,high,Alice,12-10-2020,Nathan,13-10-2020,15,Eugene,44.04791641,-123.1409988
9,Azure Service Bus,How do I handle a dead letter queue in Azure Service Bus?,"1. Advanced search option to find the dead-lettered message.
2. Intelligent automation to bulk resubmit the dead-lettered messages.
3. Variety of message receval modes like Peek-lock and Deffered mode.
4. Back up and purge messages.
5. Download particular set of messages.",critical,high,Bob,03-09-2021,Iris,04-09-2021,1,Visalia,36.29280853,-119.3134842
10,Azure Service Bus,"What should I use to achieve output supporting exactly once delivery 
with Azure Stream Analytics?","Azure Stream Analytics upserts entities, so the value of a table entity will be the latest output event with the corresponding RowKey / PartitionKey combination. Therefore, to achieve exactly-once delivery, ensure that each output event has a unique RowKey / PartitionKey combination",medium,medium,Charlie,13-11-2023,Iris,15-11-2023,14,Lompoc,34.6125679,-120.4261932
11,Azure Service Bus,"I have a Service Bus Standard namespace. Why do I see charges under 
resource group '$system'?","Azure Service Bus recently upgraded the billing components. Because of this change, if you have a Service Bus Standard namespace, you may see line items for the resource '/subscriptions/<azure_subscription_id>/resourceGroups/$system/providers/Microsoft.ServiceBus/namespaces/$system' under resource group '$system'.

These charges represent the base charge per Azure subscription that has provisioned a Service Bus Standard namespace.

It's important to note that these charges aren't new, that is, they existed in the previous billing model too. The only change is that they're now listed under '$system'. It's done because of constraints in the new billing system that groups subscription level charges, not tied to a specific resource, under the '$system' resource ID.",high,low,Frank,28-05-2023,Daniel,31-05-2023,29,Pomona,34.04991913,-117.7161026
12,Azure Service Bus,Why am I not able to create a namespace after deleting it from another subscription?,"When you delete a namespace from a subscription, wait for 4 
hours before recreating it with the same name in another subscription. Otherwise, you may receive the following error message: Namespace already exists.",high,low,Alice,26-10-2023,Daniel,27-10-2023,12,Lompoc,34.6125679,-120.4261932
13,Azure Service Bus,I am getting an ERROR: ImageBuildFailure,"This error is returned when the environment (docker image) is being built. You can check the build log for more information on the failure(s). The 
build log is located in the default storage for your Azure Machine Learning workspace. The exact location may be returned as part of the error. For example, ""The build log is available in the workspace blob store '[storage-account-name]' under the path '/azureml/ImageLogs/your-image-id/build.log'"". In this case, ""azureml"" is the name of the blob container in the storage account.",critical,high,David,26-10-2023,Daniel,27-10-2023,32,Elmhurst,40.74718475,-73.87696838
14,Azure Service Bus,The TokenProvider object couldn't acquire a token,"Make sure the token provider is created with the correct values. 
Check the configuration of the Access Control Service.",high,medium,Alice,05-04-2022,Finn,07-04-2022,30,Crystal Lake,42.23450089,-88.23731995
15,Azure Service Bus,Service isn't able to process the request at this time.,"Client can wait for a period of time, then retry the operation.",medium,medium,Alice,17-09-2022,Iris,18-09-2022,35,Van Nuys,34.1971817,-118.4865265
16,Azure - ADL,The underlying connection was closed: Could not establish trust relationship for the SSL/TLS secure channel.,"As a workaround, use the staged copy to skip the Transport Layer Security (TLS) validation for Azure Data Lake Storage Gen1. You need to reproduce this issue and gather the network monitor (netmon) trace, and then engage your network team to check the local network configuration.",low,high,Grace,17-09-2022,Nathan,19-09-2022,6,Levittown,40.72494888,-73.52056122
17,Azure - ADL,The Azure Data Factory remote server returned an error: (403) Forbidden,Grant appropriate permissions to all the folders and subfolders you need to copy.,medium,low,Bob,17-09-2022,Olivia,18-09-2022,6,Bakersfield,35.29149246,-118.9143066
18,Azure - ADL,Failed to get access token by using service principal. ADAL Error: service_unavailable,Rerun the copy activity after several minutes.,medium,medium,David,31-01-2021,Nathan,01-02-2021,33,Chicago,41.89509964,-87.73982239
19,Azure - ADL,Request to Azure Data Lake Storage Gen2 account caused a timeout error,"Place your Self-hosted IR machine and target Azure Data Lake Storage Gen2 account in the same region, if possible. This can help avoid a random timeout error and produce better performance.

Check whether there's a special network setting, such as ExpressRoute, and ensure that the network has enough bandwidth. We suggest that you lower the Self-hosted IR concurrent jobs setting when the overall bandwidth is low. Doing so can help avoid network resource competition across multiple concurrent jobs.

If the file size is moderate or small, use a smaller block size for nonbinary copy to mitigate such a timeout error.",critical,high,Alice,31-01-2021,Madison,01-02-2021,31,Elyria,41.36125946,-82.11012268
20,Azure - ADL,The copy activity is not able to pick files from Azure Data Lake Storage Gen2,"Change the file name to avoid the reserved list for Parquet below:

The file name contains _metadata.
The file name starts with . (dot).",high,low,Grace,31-01-2021,Katherine,02-02-2021,4,West Chester,39.96376801,-75.60626221
21,Azure - ADL,I am getting ADLSGen2ForbiddenError in Azure Data Lake,"Check your Azure storage account network settings to see whether the public network access is disabled. If disabled, use a managed virtual network integration runtime and create a private endpoint to access. For more information, see Managed virtual network and Build a copy pipeline using managed VNet and private endpoints.

If you have enabled selected virtual networks and IP addresses in your Azure storage account network setting:

It's possible because some IP address ranges of your integration runtime are not allowed by your storage account firewall settings. Add the Azure integration runtime IP addresses or the self-hosted integration runtime IP address to your storage account firewall. For Azure integration runtime IP addresses, see Azure Integration Runtime IP addresses, and to learn how to add IP ranges in the storage account firewall, see Managing IP network rules.

If you allow trusted Azure services to access this storage account in the firewall, you must use managed identity authentication in copy activity.

For more information about the Azure storage account firewalls settings, see Configure Azure Storage firewalls and virtual networks.

If you use service principal or managed identity authentication, grant service principal or managed identity appropriate permissions to do copy. For source, at least the Storage Blob Data Reader role. For sink, at least the Storage Blob Data Contributor role. For more information, see Copy and transform data in Azure Data Lake Storage Gen2.",medium,medium,Alice,06-11-2023,Harry,08-11-2023,4,Long Beach,33.85414505,-118.191597
22,Azure - ADL,Error code: 3200 The Databricks access token has expired,"By default, the Azure Databricks access token is valid for 90 days. Create a new token and update the linked service.",medium,low,Charlie,09-11-2023,Gabriella,11-11-2023,19,Hayward,37.67551041,-122.0496826
23,Azure - ADL,Error code: 3201 Missing required field: settings.task.notebook_task.notebook_path.,Specify the notebook path in the Databricks activity,medium,low,Charlie,17-06-2023,Gabriella,19-06-2023,26,Palatine,42.11053467,-88.10240173
24,Azure - ADL,Invalid Python file URI... Please visit Databricks user guide for supported URI schemes.," Specify either absolute paths for workspace-addressing schemes, or dbfs:/folder/subfolder/foo.py for files stored in the Databricks File System (DFS)",low,medium,Emily,06-09-2022,Lucas,07-09-2022,18,Ventura,34.2395134,-119.1972198
25,Azure - ADL,"Error code: 3202 There were already 1000 jobs created in past 3600 seconds, exceeding rate limit: 1000 job creations per 3600 seconds."," Check all pipelines that use this Databricks workspace for their job creation rate. If pipelines launched too many Databricks runs in aggregate, migrate some pipelines to a new workspace.",medium,high,Bob,29-08-2022,Katherine,30-08-2022,15,Riverside,32.8493309,-116.6139984
26,Azure - ADL,"Error code: 3203 The cluster is in Terminated state, not available to receive jobs. Please fix the cluster or retry later.","To avoid this error, use job clusters.",high,medium,Alice,08-11-2022,Finn,10-11-2022,20,Caguas,18.29146767,-66.37060547
27,Azure - ADL,Error code: 3208 An error occurred while sending the request.,"If you're using a self-hosted integration runtime, make sure that the network connection is reliable from the integration runtime nodes. If you're using Azure integration runtime, retry usually works.",high,medium,Bob,08-11-2022,James,11-11-2022,21,Amarillo,35.18754196,-101.8676224
28,Azure - ADL,We cannot accept your job at this moment. The maximum number of queued jobs for your account is 200.,"Reduce the number of submitted jobs to Data Lake Analytics. Either change triggers and concurrency settings on activities, or increase the limits on Data Lake Analytics.",high,medium,Bob,12-06-2022,Iris,15-06-2022,10,Caguas,18.27551079,-66.37049866
29,Azure - ADL,This job was rejected because it requires 24 AUs. This account's administrator-defined policy prevents a job from using more than 5 AUs.,"Reduce the number of submitted jobs to Data Lake Analytics. Either change triggers and concurrency settings on activities, or increase the limits on Data Lake Analytics.",medium,low,Alice,11-10-2021,Iris,13-10-2021,18,Caguas,18.27551079,-66.37049866
30,Azure - ADL,Error code: 2705 Forbidden. ACL verification failed. Either the resource does not exist or the user is not authorized to perform the requested operation.<br/> <br/> User is not able to access Data Lake Store. <br/> <br/> User is not authorized to use Data Lake Analytics.,"Verify that the service principal or certificate that the user provides for Data Lake Analytics jobs has access to both the Data Lake Analytics account, and the default Data Lake Storage instance from the root folder.",low,medium,Henry,11-10-2021,Nathan,12-10-2021,14,Caguas,18.2353611,-66.37051392
31,Azure - ADL,"Unable to service the submit job request as templeton service is busy with too many submit job requests or Queue root.joblauncher already has 500 applications, cannot accept submission of application",Limit the number of concurrent jobs submitted to HDInsight. Refer to activity concurrency if the jobs are being submitted by the same activity. Change the triggers so the concurrent pipeline runs are spread out over time.,medium,medium,Frank,09-06-2020,Iris,11-06-2020,13,Humacao,18.1501503,-65.82595062
32,Azure - ADL,"If the statement in the mistake notification reads something like this Due to the job submission's lateness, a task was cancelled.
","The problem could be either general HDInsight connectivity or network connectivity. First confirm that the HDInsight Ambari UI is available from any browser. Then check that your credentials are still valid.

If you're using a self-hosted integrated runtime (IR), perform this step from the VM or machine where the self-hosted IR is installed. Then try submitting the job again.",high,low,Grace,09-06-2020,Iris,11-06-2020,28,Los Angeles,34.06435013,-118.437088
33,Azure - ADL,A task has been cancelled. or similar language in the error notification indicates that the deadline for submitting the task has passed.,,medium,low,Emily,09-06-2020,Gabriella,10-06-2020,1,Los Angeles,34.06435013,-118.437088
34,Azure - ADL,"When the error message contains a message similar to 502 - Web server received an invalid response while acting as a gateway or proxy server, this error is returned by HDInsight service.","A 502 error often occurs when your Ambari Server process was shut down. You can restart the Ambari Services by rebooting the head node.
Connect to one of your nodes on HDInsight using SSH.
Identify your active head node host by running ping headnodehost.
Connect to your active head node as Ambari Server sits on the active head node using SSH.
Reboot the active head node.",high,low,Bob,09-06-2020,Katherine,12-06-2020,7,Caguas,18.2363205,-66.3706131
35,Azure - ADL,Could not get the status of the application '%physicalJobId;' from the HDInsight service. Received the following error: %message;. Please refer to HDInsight troubleshooting documentation or contact their support for further assistance.,"This error occurs when the service doesn't receive a response from HDInsight cluster when attempting to request the status of the running job. This issue might be on the cluster itself, or HDInsight service might have an outage.",low,medium,Grace,09-06-2020,Emma,11-06-2020,33,Caguas,18.2363205,-66.3706131
36,Azure - ADL,Failed to get access token by using service principal. ADAL Error: service_unavailable,Rerun the copy activity after several minutes.,medium,medium,Emily,09-06-2020,Lucas,10-06-2020,13,Chicago,41.89527512,-87.73571014
37,Azure - AKS,Client can't reach an Azure Kubernetes Service (AKS) cluster's API,"Ensure that your client's IP address is within the ranges authorized by the cluster's API server:

1. Find your local IP address. For information on how to find it on Windows and Linux, see How to find my IP.

2. Update the range that's authorized by the API server by using the az aks update command in Azure CLI. Authorize your client's IP address.",high,medium,Alice,06-09-2022,Harry,09-09-2022,34,Vacaville,38.34882355,-121.9724197
38,Azure - AKS,"when I try to upgrade an Azure Kubernetes Service (AKS) cluster getting 
error as ""PodDrainFailure""","1. Adjust the PDB to enable pod draining. Generally, The allowed disruption is controlled by the Min Available / Max unavailable or Running pods / Replicas parameter. You can modify the Min Available / Max unavailable parameter at the PDB level or increase the number of Running pods / Replicas to push the Allowed Disruption value to 1 or greater.
2.Try again to upgrade the AKS cluster to the same version that you tried to upgrade to previously. This process will trigger a reconciliation.",high,high,David,29-08-2022,Katherine,31-08-2022,11,Rego Park,40.73192978,-73.8688736
39,Azure - AKS," AKS cluster upgrade fails, and getting ""PublicIPCountLimitReached"" as 
error message","To raise the limit or quota for your subscription, go to the Azure portal, file a 
Service and subscription limits (quotas) support ticket, and set the quota type to Networking.

After the quota change takes effect, try to upgrade the cluster to the same version that you previously tried to upgrade to. This process will trigger a reconciliation.",medium,medium,Henry,08-11-2022,Daniel,10-11-2022,10,South San Francisco,37.65774155,-122.4140701
40,Azure - AKS,"""SubnetIsFull"" error code during an AKS cluster upgrade","Reduce the cluster nodes to reserve IP addresses for the upgrade.

If scaling down isn't an option, and your virtual network CIDR has enough IP addresses, try to add a node pool that has a unique subnet:

1. Add a new user node pool in the virtual network on a larger subnet.
2. Switch the original node pool to a system node pool type.
3. Scale up the user node pool.
4. Scale down the original node pool.",high,low,David,08-11-2022,Madison,10-11-2022,35,New York,40.81129837,-73.94896698
41,Azure - AKS,"Failed to upgrade or scale Azure Kubernetes Service cluster due to missing 
Log Analytics workspace","If it has been more than 14 days since the workspace was deleted, disable monitoring on the AKS cluster and then run the upgrade or scale operation again.

To disable monitoring on the AKS cluster, run the following command:

az aks disable-addons -a monitoring -g <clusterRG> -n <clusterName>
If the same error occurs while disabling the monitoring add-on, recreate the missing Log Analytics workspace and then run the upgrade or scale operation again.",low,high,Charlie,12-06-2022,Katherine,13-06-2022,15,Long Beach,33.78982544,-118.1819992
42,Azure - AKS,"Upgrades to Kubernetes 1.16 fail when node labels have a kubernetes.io 
prefix","To mitigate this issue:

Upgrade your cluster control plane to 1.16 or later.
Add a new node pool on 1.16 or higher without the unsupported kubernetes.io labels.
Delete the older node pool.",medium,medium,Charlie,11-10-2021,Iris,14-10-2021,7,Houston,29.7805748,-95.17199707
43,Azure - AKS,"CannotDeleteLoadBalancerWithPrivateLinkService or 
PrivateLinkServiceWithPrivateEndpointConnectionsCannotBeDeleted error code","Make sure that the private link service isn't associated with any private endpoint
 connections. Delete all private endpoint connections before you delete the private link service.",critical,high,Grace,11-10-2021,James,13-10-2021,15,New Orleans,29.96966934,-90.09384918
44,Azure - AKS,"PublicIPAddressCannotBeDeleted, InUseSubnetCannotBeDeleted, or 
InUseNetworkSecurityGroupCannotBeDeleted error code","1. Remove all public IP addresses that are associated with Azure Load Balancer and the resource that's used by the subnet. For more information, see View, modify settings for, or delete a public IP address.

2. In the load balancer, remove the rules for Load Balance rules, Health probes, and Backend pools.

3. For the NSG and subnet, remove all associated rules.",medium,medium,David,09-06-2020,Olivia,12-06-2020,10,Santa Cruz,36.97051239,-122.0238266
45,Azure - AKS,"when I try to delete a Microsoft Azure Kubernetes Service (AKS) cluster 
getting error as InUseRouteTableCannotBeDeleted error code",Remove the associated subnet in the route table.,high,medium,Grace,09-06-2020,Iris,10-06-2020,16,Santa Cruz,36.97051239,-122.0238266
46,Azure - AKS,"When I tried to delete an AKS cluster while the virtual machine scale set was still using the associated public IP address or network security group (NSG) getting LoadBalancerInUseByVirtualMachineScaleSet or 
NetworkSecurityGroupInUseByVirtualMachineScaleSet error code","Remove all public IP addresses that are associated with the subnet, and remove 
the NSG that's used by the subnet.",medium,high,Alice,09-06-2020,Harry,11-06-2020,5,Rome,43.21662521,-75.45603943
47,Azure - AKS,"when I try to delete a Microsoft Azure Kubernetes Service (AKS) getting 
clusterRequestDisallowedByPolicy error(for cluster deletions)","Verify that you have permission to make any changes to policy services. If you 
don't have permission, find someone who has access so that they can make the necessary changes. Also, check the policy name that's causing the problem, and then temporarily deny that rule so that you (or someone who has permission) can do the delete operation.",low,medium,Frank,09-06-2020,Harry,10-06-2020,33,Mount Pleasant,43.61513138,-84.60793304
48,Azure - AKS,"Getting error asTooManyRequestsReceived or 
SubscriptionRequestsThrottled when I try to delete a Microsoft Azure Kubernetes Service (AKS) cluster","The HTTP response includes a Retry-After value. This specifies the number of 
seconds that your application should wait (or sleep) before it sends the next request. If you send a request before the retry value has elapsed, your request isn't processed, and a new retry value is returned",medium,low,Alice,09-06-2020,Olivia,12-06-2020,29,Albuquerque,35.02748108,-106.7064819
49,Azure - AKS,"I get an ""insufficientSubnetSize"" error when I deploy an AKS cluster that 
uses advanced networking","Because you can't update an existing subnet's CIDR range, you must have permission to create a new subnet to resolve this issue. Follow these steps:

1. Rebuild a new subnet that has a larger CIDR range that's sufficient for operation goals.

2.Create a new subnet that has a new non-overlapping range.

3.Create a new node pool on the new subnet.

4. Drain pods from the old node pool that resides in the old subnet that will be replaced.

5.Delete the old subnet and old node pool.",medium,medium,Grace,09-06-2020,Finn,12-06-2020,35,Columbus,30.27972984,-97.83985138
50,Azure - AKS,"Cluster autoscaler fails to scale with ""failed to fix node group sizes"" error","To get out of this state, disable and re-enable the cluster autoscaler.",medium,medium,Alice,09-06-2020,Nathan,12-06-2020,15,South Ozone Park,40.67544937,-73.81114197
51,Azure - AKS,Node Not Ready failures that are followed by recoveries error,"To prevent this issue from occurring in the future, take one or more of the following actions:

1. Make sure that your service tier is fully paid for.
2. Reduce the number of watch and get requests to the API server.
3. Replace the node pool with a healthy node pool.",medium,low,Bob,15-04-2023,Iris,16-04-2023,3,New Orleans,29.98578072,-90.06645203
52,Azure - AKS,Can't view resources in Kubernetes resource viewer in Azure portal,"Make sure that when you run the az aks create or az aks update command in 
Azure CLI, the --api-server-authorized-ip-ranges parameter includes access for the local client computer to the IP addresses or IP address ranges from which the portal is being browsed.",medium,high,Henry,05-12-2022,Nathan,06-12-2022,10,Apex,35.73103714,-78.85575104
53,Azure - AKS,Getting an error when I try to upgrade or scale a Microsoft Azure Kubernetes Service (AKS) cluster,"To resolve these scenarios, follow these steps:

1. Scale your cluster back to a stable goal state within the quota.

2. Request an increase in your resource quota.

3. Try to scale up again beyond the initial quota limits.

4. Retry the original operation. This second operation should bring your cluster to a successful state.",medium,low,Grace,22-11-2021,Lucas,23-11-2021,18,Opa Locka,25.94878006,-80.28707886
54,Azure - AKS,Insufficient subnet size error while deploying an AKS cluster with advanced networking,"Create new subnets. Because you can't update an existing subnet's CIDR range, you'll need to be granted the permission to create a new subnet.

Rebuild a new subnet with a larger CIDR range that's sufficient for operation goals by following these steps:

1. Create a new subnet with a larger, non-overlapping range.

2. Create a new node pool on the new subnet.

3. Drain the pods from the old node pool that resides in the old subnet.

4. Delete the old subnet and old node pool.",high,high,Henry,22-11-2021,James,24-11-2021,15,Mount Prospect,42.03620529,-87.96143341
55,Azure - AKS,Missing or invalid service principal when creating an AKS cluster,"Make sure that there's a valid, findable service principal. To do this, use one of the following methods:

During cluster creation, use an existing service principal that has already propagated across regions to pass into AKS.

If you use automation scripts, add time delays between service principal creation and AKS cluster creation.

If you use the Azure portal, return to the cluster settings after you try to create the cluster, and then retry the validation page after a few minutes.",medium,low,Alice,11-11-2020,Olivia,14-11-2020,19,Germantown,39.19226837,-77.24241638
56,Azure - AKS,"when I am  creating an AKS cluster getting errors after restricting egress 
traffic in AKS","Verify that your configuration doesn't conflict with any of the required or optionally recommended settings for the following items:

1. Outbound ports
2. Network rules
3. Fully qualified domain names (FQDNs)
4. Application rules",medium,low,Henry,13-05-2020,Iris,15-05-2020,19,Highland,34.12934113,-117.1800232
57,Azure - AKS,"Error: TCP time-outs when kubectl or other third-party tools connect to the
 API server","Make sure the nodes that host this pod aren't overly utilized or under stress. 
Consider moving the nodes to their own system node pool.",low,low,Emily,27-08-2020,Madison,30-08-2020,32,Asheboro,35.70111466,-79.82025147
58,Azure Security IAM,How can I identify how and when key vaults are accessed?,"After you create one or more key vaults, you'll likely want to monitor how and 
when your key vaults are accessed, and by whom. You can do monitoring by enabling logging for Azure Key Vault",medium,low,Charlie,27-08-2020,Katherine,28-08-2020,11,Tracy,33.20634842,-117.23069
59,Azure Security IAM,"How can I monitor vault availability, service latency periods or other 
performance metrics for key vault?","As you start to scale your service, the number of requests sent to your key vault 
will rise. Such demand has a potential to increase the latency of your requests and in extreme cases, cause your requests to be throttled which will degrade the performance of your service. You can monitor key vault performance metrics and get alerted for specific thresholds",low,medium,Henry,27-08-2020,Gabriella,29-08-2020,34,Richardson,32.99349213,-96.69972992
60,Azure Security IAM,"I'm not able to modify access policy, how can it be enabled?","The user needs to have sufficient Azure AD permissions to modify access policy. 
In this case, the user would need to have higher contributor role.",high,high,Alice,09-12-2022,Gabriella,12-12-2022,26,Moreno Valley,33.92159271,-117.263176
61,Azure Security IAM,How can I give the AD group access to the key vault?,"Give the AD group permissions to your key vault using the Azure CLI az keyvault set-policy command, or the Azure PowerShell Set-AzKeyVaultAccessPolicy cmdlet.

The application also needs at least one Identity and Access Management (IAM) role assigned to the key vault. Otherwise it will not be able to log in and will fail with insufficient rights to access the subscription. Azure AD Groups with Managed Identities may require up to eight hours to refresh tokens and become effective.",low,medium,David,09-12-2022,Nathan,12-12-2022,1,Longmont,40.1901207,-105.1010666
62,Azure Security IAM,Unable to assign a role using a service principal with Azure CLI,"There are two ways to potentially resolve this error. The first way is to assign the Directory Readers role to the service principal so that it can read data in the directory.

The second way to resolve this error is to create the role assignment by using the --assignee-object-id parameter instead of --assignee. By using --assignee-object-id, Azure CLI will skip the Azure AD lookup. You'll need to get the object ID of the user, group, or application that you want to assign the role to.",low,medium,Frank,16-07-2023,Iris,19-07-2023,26,Pasadena,39.11119843,-76.48913574
63,Azure Security IAM,"ClientCertificateCredential authentication issueClient assertion contains 
an invalid signature.",Ensure the specified certificate has been uploaded to the AAD application registration.,low,medium,Grace,25-09-2021,Katherine,26-09-2021,30,Florissant,38.77356339,-90.28000641
64,Azure Security IAM,"ManagedIdentityCredential authentication unavailable, no managed 
identity endpoint found","Ensure the managed identity has been properly configured on the App Service. 
Verify the App Service environment is properly configured and the managed identity endpoint is available. ",medium,low,David,16-01-2022,Gabriella,19-01-2022,19,New York,40.62457657,-73.94354248
65,Azure Security IAM,"when app is deployed and when running locally getting error 
CredentialUnavailableException:No Managed Identity endpoint found","Verify the pod is labeled correctly. This also occurs when a correctly labeled 
pod authenticates before the identity is ready. To prevent initialization races, configure NMI to set the Retry-After header in its responses",high,medium,Bob,16-01-2022,Olivia,18-01-2022,33,Newark,39.83205795,-75.75762177
66,Azure Security IAM,Deleted or rejected private end point still shows Aprroved in ADF,"You should delete the managed private end point in ADF once existing private
 endpoints are rejected/deleted from source/sink datasets.",high,high,Henry,17-09-2021,Harry,18-09-2021,5,Chicago,41.89448166,-87.77452087
67,Azure Security IAM,Connection error in public endpoint,"1. Having private endpoint enabled on the source and also the sink side when using the Managed VNet IR.
2. If you still want to use the public endpoint, you can switch to public IR only instead of using the Managed VNet IR for the source and the sink. Even if you switch back to public IR, the service may still use the Managed VNet IR if the Managed VNet IR is still there.",critical,high,Emily,17-09-2021,Madison,18-09-2021,4,East Lansing,42.9221611,-84.01567841
68,Azure Security IAM,Not able to use self-hosted IR to bridge two on-premises datastores,"Install drivers for both the source and destination datastores on the destination IR, and make sure that it can access the source datastore.

If the traffic can't pass through the network between two datastores (for example, they're configured in two virtual networks), you might not finish copying in one activity even with the IR installed. If you can't finish copying in a single activity, you can create two copy activities with two IRs, each in a VENT:

1.Copy one IR from datastore 1 to Azure Blob Storage
2. Copy another IR from Azure Blob Storage to datastore 2.
This solution could simulate the requirement to use the IR to create a bridge that connects two disconnected datastores.",low,medium,Henry,17-09-2021,James,20-09-2021,7,Knoxville,35.94585037,-84.09391022
69,Azure Security IAM,Unable to register the self-hosted IR,Use localhost IP address 127.0.0.1 to host the file and resolve the issue.,medium,low,Frank,17-09-2021,Daniel,19-09-2021,5,Pico Rivera,34.00259781,-118.0799789
70,Azure Security IAM,"I can sign in to  Azure portal, but I see the error, No subscriptions found","To fix this issue:

1. Verify that the correct Azure directory is selected by selecting your account at the top-right corner.
2. If the correct Azure directory is selected, but you still receive the error message, have your account added as an Owner.",low,high,David,17-09-2021,Finn,20-09-2021,11,Miami,25.92886925,-80.16287231
71,Azure Security IAM,How do I check my current consumption level?,Azure customers can view their current usage levels in Cost Management,medium,low,Charlie,17-09-2021,Madison,18-09-2021,3,Mount Prospect,42.03620529,-87.96143341
72,Azure Security IAM,Unable to remove a credit card from a saved billing payment method,"By design, you can't remove a credit card from the active subscription.

If an existing card has to be deleted, one of the following actions is required:

1. A new card must be added to the subscription so that the old payment instrument can be successfully deleted.
2. You can cancel the subscription to delete the subscription permanently and then remove the card.",medium,high,Emily,17-09-2021,James,18-09-2021,15,Granite City,38.69002152,-90.14477539
73,Azure Security IAM,VisualStudioCredential authentication issue: Failed To Read Credentials,"1. In Visual Studio select the Tools > Options menu to launch the Options dialog.
2. Navigate to the Azure Service Authentication options to sign in with your Azure Active Directory account.
3. If you already had logged in to your account, try logging out and logging in again as that will repopulate the cache and potentially mitigate the error you're getting.",high,high,David,19-10-2023,Olivia,21-10-2023,33,San Antonio,32.87078095,-97.32335663
74,Azure Security IAM,AzureCliCredential authentication issue:Azure CLI not installed,"1. Ensure the Azure CLI is properly installed. 
2. Validate the installation location has been added to the PATH environment variable.",medium,low,Emily,08-12-2022,Gabriella,09-12-2022,29,Walnut,33.80669785,-118.0159607
75,Azure Security IAM,"RequestFailedException raised from the client with a status code of 401 or 
403","1. Enable logging to determine which credential in the chain returned the authenticating token.
2. In the case a credential other than the expected is returning a token, bypass this by either signing out of the corresponding development tool, or excluding the credential with the ExcludeXXXCredential property in the DefaultAzureCredentialOptions
3. Ensure that the correct role is assigned to the account being used. For example, a service specific role rather than the subscription Owner role.",low,low,Charlie,08-12-2022,Lucas,10-12-2022,10,Highland,34.12934113,-117.1800232
76,Azure Security IAM,"UsernamePasswordCredential authentication Error Code: AADSTS50126
",Ensure the username and password provided when constructing the credential are valid.,medium,medium,Alice,27-12-2021,Iris,28-12-2021,20,San Pablo,37.95482636,-122.332962
77,Azure Security IAM,"CredentialUnavailableException: The requested identity hasn't been 
assigned to this resource. ","If using a user assigned identity, ensure the specified clientId is correct.
If using a system assigned identity, make sure it has been enabled properly. ",medium,high,Henry,27-12-2021,Daniel,29-12-2021,2,Memphis,35.21362686,-89.82608032
78,Azure Security IAM,"CredentialUnavailableException: ManagedIdentityCredential 
authentication unavailable.","Ensure the managed identity has been properly configured on the App Service. 

Verify the App Service environment is properly configured and the managed identity endpoint is available",low,medium,David,27-12-2021,Nathan,28-12-2021,25,Richardson,32.99349213,-96.69972992
79,Cloud Deployment,"Error: ""Dependency not found"" or ""Incompatible version"" when deploying an application or service.",Review the application's dependencies and ensure that all required dependencies are available and compatible with the deployed environment. Update or adjust dependency versions as needed.,medium,high,Charlie,09-12-2023,Katherine,11-12-2023,19,Brooklyn,40.63588715,-73.94223023
80,Cloud Deployment,"Error: ""Permission denied"" or ""Insufficient permissions"" during 
deployment.","Ensure that the user or service account performing the 
deployment has the necessary roles and permissions. Grant the appropriate IAM roles, such as roles/editor or roles/clouddeploy.admin, to the user or service account.",medium,low,Grace,09-12-2023,Lucas,12-12-2023,11,Fullerton,33.86329651,-117.9716263
81,Cloud Deployment,"Error: ""Quota exceeded"" or ""Resource limit reached"" when deploying 
resources.","Check the quota limits for the specific resource you are 
trying to deploy. If the quota is insufficient, request a quota increase by following the appropriate process in the GCP Console or contacting GCP Support.",medium,high,Emily,09-12-2023,Emma,10-12-2023,23,Cincinnati,39.36290741,-84.39199066
82,Cloud Deployment,"Error: ""Failed to create network"" or ""Failed to configure firewall rules"" 
during deployment.","Ensure that the specified network configuration and firewall
 rules are valid. Verify that the specified subnets, IP ranges, and firewall rules do not conflict with existing resources or rules.",critical,high,Alice,26-11-2020,Iris,27-11-2020,14,San Diego,32.75012589,-117.1374207
83,Cloud Deployment,"Error: ""Invalid YAML syntax"" or ""Configuration file contains errors"" 
during deployment.","Validate your YAML configuration files using a YAML linter or
 online validator. Ensure that the YAML syntax is correct and the configuration follows the expected structure and format for the deployment tool or service you are using.",medium,low,Frank,12-06-2022,Nathan,15-06-2022,14,San Antonio,29.38037109,-98.6422348
84,Cloud Repository,"Error: ""Permission denied"" or ""Insufficient permissions"" when accessing
 or performing operations in Cloud Repository.","Ensure that the user or service account has the necessary roles and
permissions. Grant the appropriate IAM roles, such as roles/source.reader or roles/source.writer, to the user or service account.",medium,low,Alice,12-06-2022,Iris,14-06-2022,33,Sunnyvale,37.36976242,-122.0313721
85,Cloud Repository,"Error: ""Repository not found"" or ""No repository exists with the given 
name.""","Double-check the repository name and ensure that it exists in your 
project and is spelled correctly. Use the correct project ID or name along with the repository name when referencing it.",low,medium,Bob,12-10-2020,Katherine,15-10-2020,1,Lindenhurst,40.68665695,-73.37553406
86,Cloud Repository,"""Authentication failed"" or ""Invalid credentials"" when attempting to 
authenticate with Cloud Repository.","Verify that you are using valid credentials for accessing Cloud 
Repository. Ensure that the authentication method, such as using SSH keys or gcloud command-line tool with the correct configuration, is set up correctly.",high,medium,Alice,12-10-2020,Katherine,13-10-2020,14,Los Angeles,34.03234482,-118.3598175
87,Cloud Repository,"""Failed to push to repository"" or ""Failed to clone repository"" when 
performing Git operations.","Solution:
1. Check your network connectivity and ensure you have a stable internet connection.
2. Verify that the repository URL is correct and properly formatted.
3. Make sure you have the necessary permissions to push or clone the repository.",medium,high,Bob,03-09-2021,Gabriella,04-09-2021,28,Middletown,39.48305893,-84.33435059
88,Cloud Repository,"Error: ""Branch not found"" or ""Tag not found"" when attempting to access 
a specific branch or tag.","Ensure that the branch or tag exists in the repository. Double-check 
the spelling and case sensitivity when referencing the branch or tag name.",medium,low,Henry,13-11-2023,Emma,14-11-2023,23,Jacksonville,30.19924736,-81.72353363
89,Cloud Scheduler,"Error: ""Permission denied"" or ""Insufficient permissions"" when 
attempting to create or manage Cloud Scheduler jobs.","Ensure that the user or service account has the necessary roles and 
permissions. Grant the appropriate IAM roles, such as roles/cloudscheduler.admin or roles/cloudscheduler.editor, to the user or service account.",high,high,Bob,28-05-2023,Madison,31-05-2023,34,San Antonio,29.52998352,-98.60829163
90,Cloud Scheduler,"Error: ""Invalid job configuration"" or ""Failed to create job"" due to 
incorrect or missing configuration settings.","Double-check the job configuration, including the target HTTP/HTTPS 
endpoint, cron schedule, time zone, and payload (if applicable). Verify that all required fields are provided and correctly formatted.",high,medium,Bob,26-10-2023,Katherine,29-10-2023,5,Lawrenceville,33.94185257,-84.08663178
91,Cloud Scheduler,"Error: ""Authentication failed"" or ""Invalid credentials"" when 
authenticating requests triggered by Cloud Scheduler.","Ensure that the target endpoint or service being invoked by the Cloud 
Scheduler job is configured to accept and validate the authentication credentials. Verify that the authentication method and credentials used are correct and valid.",low,low,Bob,26-10-2023,Iris,27-10-2023,21,Orlando,28.55625916,-81.27587128
92,Cloud Scheduler,"Error: ""Failed to reach the target endpoint"" or ""Target endpoint returned
 an error"" when invoking the specified HTTP/HTTPS endpoint.","Solution:
1. Check the target endpoint's availability and connectivity. Verify that the endpoint is accessible from the internet and is not blocked by firewalls or other network restrictions.
2. Ensure that the endpoint URL is correct and properly formatted.
3. Inspect the logs or error messages returned by the target endpoint to identify and address the specific issue.",high,low,Emily,05-04-2022,Madison,07-04-2022,36,Fort Washington,38.74266434,-76.9917984
93,Cloud Scheduler,"Error: ""Invalid cron schedule"" or ""Failed to parse cron expression"" due to
 an incorrect cron schedule format.","Review the cron schedule syntax and ensure that it adheres to the 
correct format. Use tools or online cron expression validators to verify the syntax and correctness of the cron schedule.",medium,low,Bob,17-09-2022,Finn,19-09-2022,1,Pomona,34.07833099,-117.7349777